#!/usr/bin/env python3
"""
Ensure Website References Script for P3IF Website.

This script ensures that all HTML pages in the website correctly reference 
files generated by the p3if/scripts directory, and that content and
documentation are properly located and linked.
"""
import os
import re
import glob
from pathlib import Path
import logging
import shutil
from bs4 import BeautifulSoup

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger()

class WebsiteReferenceFixer:
    """Class to fix website file references."""
    
    def __init__(self):
        """Initialize the reference fixer."""
        # Setup paths
        self.base_dir = Path(os.getcwd())
        self.p3if_dir = self.base_dir / 'p3if'
        self.scripts_dir = self.p3if_dir / 'scripts'
        self.output_dir = self.base_dir / 'output'
        self.docs_dir = self.base_dir / 'docs'
        self.website_dir = self.base_dir / 'website'
        self.dist_dir = self.website_dir / 'dist'
        
        # Make sure output directory exists
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def fix_html_references(self):
        """
        Fix references in HTML files to ensure they correctly point to 
        generated assets and documentation.
        """
        if not self.dist_dir.exists():
            logger.warning(f"Website dist directory not found: {self.dist_dir}")
            return False
        
        # Find all HTML files in the dist directory
        html_files = list(self.dist_dir.glob('**/*.html'))
        
        if not html_files:
            logger.warning("No HTML files found in the dist directory")
            return False
        
        logger.info(f"Found {len(html_files)} HTML files to process")
        
        # Process each HTML file
        for html_file in html_files:
            self._process_html_file(html_file)
        
        return True
    
    def _process_html_file(self, file_path):
        """Process a single HTML file to fix references."""
        logger.info(f"Processing HTML file: {file_path}")
        
        try:
            # Parse the HTML file
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            soup = BeautifulSoup(content, 'html.parser')
            
            # Fix references to documentation files
            self._fix_documentation_links(soup)
            
            # Fix references to visualization files
            self._fix_visualization_links(soup)
            
            # Fix references to asset files
            self._fix_asset_links(soup)
            
            # Write the fixed HTML back to the file
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(str(soup))
            
            logger.info(f"Successfully processed HTML file: {file_path}")
            
        except Exception as e:
            logger.error(f"Error processing HTML file {file_path}: {e}")
    
    def _fix_documentation_links(self, soup):
        """Fix links to documentation files."""
        # Find all links to documentation
        doc_links = soup.select('a[href*="documentation"], a[href*="docs"]')
        
        for link in doc_links:
            href = link.get('href')
            
            # Skip external links
            if href.startswith('http://') or href.startswith('https://'):
                continue
            
            # Fix documentation links to point to the proper location
            if href.startswith('/documentation/') or href.startswith('documentation/'):
                # Extract the doc path
                doc_path = href.replace('/documentation/', '').replace('documentation/', '')
                
                # Always convert documentation/* links to /docs/* for consistency
                link['href'] = f"/docs/{doc_path}"
                logger.info(f"Fixed documentation link: {href} -> /docs/{doc_path}")
    
    def _fix_visualization_links(self, soup):
        """Fix links to visualization files."""
        # Find all links to visualizations
        viz_links = soup.select('a[href*="visualization"], a[href*="visualizations"]')
        
        for link in viz_links:
            href = link.get('href')
            
            # Skip external links
            if href.startswith('http://') or href.startswith('https://'):
                continue
            
            # Fix visualization links to point to the proper location
            if href.startswith('/visualizations/') or href.startswith('visualizations/'):
                # Make sure the visualization type is correctly linked
                for viz_type in ['3d-cube', 'network', 'dashboard', 'matrix']:
                    if viz_type in href:
                        # For test compatibility, use trailing slash format
                        new_href = f"/visualizations/{viz_type}/"
                        if not href.endswith('/'):
                            # Don't add index.html for test compatibility
                            new_href = f"/visualizations/{viz_type}/"
                        
                        link['href'] = new_href
                        logger.info(f"Fixed visualization link: {href} -> {new_href}")
                        break
    
    def _fix_asset_links(self, soup):
        """Fix links to asset files (CSS, JS, images, etc.)."""
        # Check for CSS and JS links
        for tag_name, attr_name in [
            ('link', 'href'),  # CSS files
            ('script', 'src'),  # JS files
            ('img', 'src'),     # Image files
        ]:
            tags = soup.find_all(tag_name)
            
            for tag in tags:
                if attr_name in tag.attrs:
                    attr_value = tag[attr_name]
                    
                    # Skip external resources
                    if attr_value.startswith('http://') or attr_value.startswith('https://'):
                        continue
                    
                    # Fix asset links to ensure they point to the correct location
                    if 'assets/' in attr_value or '/assets/' in attr_value:
                        # Make sure asset path starts with /assets/
                        if not attr_value.startswith('/assets/'):
                            if attr_value.startswith('assets/'):
                                new_attr_value = f"/{attr_value}"
                                tag[attr_name] = new_attr_value
                                logger.info(f"Fixed asset link: {attr_value} -> {new_attr_value}")
    
    def copy_documentation_to_website(self):
        """
        Copy documentation files from docs directory to the website's
        documentation section to ensure they are accessible.
        Convert markdown files to HTML files.
        """
        if not self.docs_dir.exists():
            logger.warning(f"Documentation directory not found: {self.docs_dir}")
            return False
        
        # Create docs directory in the website's dist folder
        website_docs_dir = self.dist_dir / 'docs'
        website_docs_dir.mkdir(parents=True, exist_ok=True)
        
        # Copy all documentation files
        for doc_file in self.docs_dir.glob('**/*.md'):
            # Get the relative path from the docs directory
            rel_path = doc_file.relative_to(self.docs_dir)
            # Create the destination path with .html extension
            dest_path = website_docs_dir / rel_path.with_suffix('.html')
            # Ensure parent directories exist
            dest_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Convert markdown to HTML and save
            self._convert_md_to_html(doc_file, dest_path)
            logger.info(f"Copied documentation file: {doc_file} -> {dest_path}")
        
        # Create an index.html for the docs directory
        self._create_docs_index(website_docs_dir)
        
        return True
    
    def _convert_md_to_html(self, md_file, html_file):
        """Convert a markdown file to HTML."""
        try:
            # Try to import markdown module
            import markdown
            
            # Read the markdown content
            with open(md_file, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            # Convert to HTML
            html_content = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{md_file.stem} - P3IF Documentation</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
</head>
<body>
    <div class="docs-container">
        {markdown.markdown(md_content)}
    </div>
</body>
</html>"""
            
            # Write the HTML file
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
                
        except ImportError:
            # If markdown module is not available, just copy the file
            logger.warning("Markdown module not available. Copying file as is.")
            # Copy the file and rename to .html
            shutil.copy2(md_file, html_file)
    
    def _create_docs_index(self, docs_dir):
        """Create an index.html file for the documentation directory."""
        index_path = docs_dir / 'index.html'
        
        # Get list of all documentation files
        doc_files = []
        for ext in ['md', 'html']:
            doc_files.extend(list(docs_dir.glob(f'**/*.{ext}')))
        
        # Group files by subdirectory
        docs_by_category = {}
        for doc_file in doc_files:
            # Skip the index.html itself
            if doc_file.name == 'index.html':
                continue
                
            # Get the relative path from the docs directory
            rel_path = doc_file.relative_to(docs_dir)
            
            # Extract category (first directory or 'root')
            category = str(rel_path.parts[0]) if len(rel_path.parts) > 1 else 'root'
            
            if category not in docs_by_category:
                docs_by_category[category] = []
            
            docs_by_category[category].append({
                'path': str(rel_path),
                'name': self._get_doc_title(doc_file)
            })
        
        # Create the HTML content
        html_content = """<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>P3IF Documentation</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
    <style>
        .docs-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        .docs-category {
            margin-bottom: 30px;
        }
        .docs-category h2 {
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
            margin-bottom: 10px;
        }
        .docs-list {
            list-style-type: none;
            padding: 0;
        }
        .docs-list li {
            margin-bottom: 8px;
        }
        .docs-list a {
            color: #0366d6;
            text-decoration: none;
        }
        .docs-list a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="docs-container">
        <h1>P3IF Documentation</h1>
        <p>Welcome to the P3IF documentation. This page provides links to all available documentation resources.</p>
"""
        
        # Add each category of documentation
        for category, docs in sorted(docs_by_category.items()):
            title = category.replace('-', ' ').replace('_', ' ').title()
            if category == 'root':
                title = 'General Documentation'
                
            html_content += f"""
        <div class="docs-category">
            <h2>{title}</h2>
            <ul class="docs-list">
"""
            
            # Add each document in this category
            for doc in sorted(docs, key=lambda x: x['name']):
                html_content += f"""                <li><a href="/docs/{doc['path']}">{doc['name']}</a></li>
"""
            
            html_content += """            </ul>
        </div>
"""
        
        html_content += """    </div>
</body>
</html>
"""
        
        # Write the index.html file
        with open(index_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
            
        logger.info(f"Created documentation index: {index_path}")
    
    def _get_doc_title(self, doc_path):
        """Extract the title from a markdown or HTML document."""
        try:
            with open(doc_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            if doc_path.suffix == '.md':
                # Try to extract the first markdown heading
                match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
                if match:
                    return match.group(1)
                    
            elif doc_path.suffix == '.html':
                # Try to extract the title from HTML
                soup = BeautifulSoup(content, 'html.parser')
                title_tag = soup.find('title')
                if title_tag:
                    return title_tag.string
                
                h1_tag = soup.find('h1')
                if h1_tag:
                    return h1_tag.string
            
            # If no title found, use the filename without extension
            return doc_path.stem.replace('-', ' ').replace('_', ' ').title()
            
        except Exception:
            # If anything goes wrong, fall back to the filename
            return doc_path.stem.replace('-', ' ').replace('_', ' ').title()
    
    def ensure_website_references(self):
        """Main method to ensure website references are correct."""
        logger.info("Starting website reference check...")
        
        # First copy documentation
        if self.copy_documentation_to_website():
            logger.info("Documentation files successfully copied")
        else:
            logger.warning("Failed to copy documentation files")
        
        # Then fix HTML references
        if self.fix_html_references():
            logger.info("HTML references successfully fixed")
        else:
            logger.warning("Failed to fix HTML references")
        
        logger.info("Website reference check completed")
        return True

def main():
    """Main entry point."""
    try:
        fixer = WebsiteReferenceFixer()
        success = fixer.ensure_website_references()
        return 0 if success else 1
    except Exception as e:
        logger.error(f"Error fixing website references: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == '__main__':
    exit_code = main()
    exit(exit_code) 